<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Making your Deep RL matters. | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Making your Deep RL matters." />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A collection of related topics about code-level optimization tricks in DRL, which dramatically changes the results." />
<meta property="og:description" content="A collection of related topics about code-level optimization tricks in DRL, which dramatically changes the results." />
<link rel="canonical" href="https://minhlong94.github.io/blog/drl/2021/09/25/Making-your-Deep-RL-matters.html" />
<meta property="og:url" content="https://minhlong94.github.io/blog/drl/2021/09/25/Making-your-Deep-RL-matters.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-09-25T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-09-25T00:00:00-05:00","url":"https://minhlong94.github.io/blog/drl/2021/09/25/Making-your-Deep-RL-matters.html","@type":"BlogPosting","dateModified":"2021-09-25T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://minhlong94.github.io/blog/drl/2021/09/25/Making-your-Deep-RL-matters.html"},"headline":"Making your Deep RL matters.","description":"A collection of related topics about code-level optimization tricks in DRL, which dramatically changes the results.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://minhlong94.github.io/blog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Making your Deep RL matters.</h1><p class="page-description">A collection of related topics about code-level optimization tricks in DRL, which dramatically changes the results.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-09-25T00:00:00-05:00" itemprop="datePublished">
        Sep 25, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      10 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#DRL">DRL</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#references">References</a></li>
<li class="toc-entry toc-h1"><a href="#why-it-matters">Why it matters?</a></li>
<li class="toc-entry toc-h1"><a href="#statistical-power-analysis-colas-et-al-2017-paper">Statistical Power Analysis (Colas et al., 2017 paper)</a>
<ul>
<li class="toc-entry toc-h2"><a href="#statistical-problem">Statistical problem</a></li>
<li class="toc-entry toc-h2"><a href="#difference-test">Difference test</a></li>
<li class="toc-entry toc-h2"><a href="#statistical-testing">Statistical testing</a></li>
<li class="toc-entry toc-h2"><a href="#the-t-test-and-welchs-t-test">The t-test and Welch’s t-test</a></li>
<li class="toc-entry toc-h2"><a href="#back-to-the-problem">Back to the problem</a></li>
<li class="toc-entry toc-h2"><a href="#estimate-the-type-i-error">Estimate the type-I error.</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#deep-reinforcement-learning-that-matters">Deep Reinforcement Learning that matters</a>
<ul>
<li class="toc-entry toc-h2"><a href="#reward-scaling">Reward Scaling</a></li>
<li class="toc-entry toc-h2"><a href="#random-seeds-and-trials">Random seeds and trials</a></li>
<li class="toc-entry toc-h2"><a href="#environment-variables">Environment variables</a></li>
<li class="toc-entry toc-h2"><a href="#implementation-tricks">Implementation tricks</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#implementation-matters-in-deep-rl-engstorm-et-al-2020-paper">Implementation Matters in Deep RL (Engstorm et al., 2020 paper)</a>
<ul>
<li class="toc-entry toc-h2"><a href="#results-comparing-4-algorithms">Results comparing 4 algorithms</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#how-to-tune-hyperparameters">How to tune hyperparameters?</a>
<ul>
<li class="toc-entry toc-h3"><a href="#network-architecture">Network Architecture</a></li>
<li class="toc-entry toc-h3"><a href="#batch-size">Batch Size</a></li>
<li class="toc-entry toc-h3"><a href="#findings-from-andrychowicz-et-al-2021-paper">Findings from Andrychowicz et al., 2021 paper</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#suggested-method-to-compare-algorithms">Suggested method to compare algorithms</a></li>
<li class="toc-entry toc-h1"><a href="#suggestions-and-conclusion">Suggestions and Conclusion</a></li>
</ul><p>A collection of implementation tricks, hyperparameter sensitivity, and others in Deep RL which I gave a presentation in my research group.</p>

<p>Author: Long M. Luu, contact: minhlong9413@gmail.com or Discord AerysS#5558.</p>

<p>“Your ResNet, batchnorm, and very deep networks don’t work here.” - Andrej Karpathy</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled.png" alt="Untitled"></p>

<h1 id="references">
<a class="anchor" href="#references" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h1>

<p>All codebases are released. Just use CatalyzeX.</p>

<p><a href="https://arxiv.org/abs/1709.06560">Deep Reinforcement Learning that Matters</a></p>

<p><a href="https://arxiv.org/abs/1806.08295">How Many Random Seeds? Statistical Power Analysis in Deep Reinforcement Learning Experiments</a></p>

<p><a href="https://arxiv.org/abs/1708.04133">Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control</a></p>

<p><a href="https://openreview.net/forum?id=r1etN1rtPB">Implementation Matters in Deep RL: A Case Study on PPO and TRPO</a></p>

<p><a href="https://arxiv.org/abs/1708.04133">Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control</a></p>

<p><a href="https://openreview.net/forum?id=nIAxjsniDzg">What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale…</a></p>

<p><a href="https://arxiv.org/abs/1812.06162">An Empirical Model of Large-Batch Training</a></p>

<p><a href="https://arxiv.org/abs/2108.13264">Deep Reinforcement Learning at the Edge of the Statistical Precipice</a></p>

<p><a href="https://arxiv.org/abs/2102.03479">Revisiting the Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning</a></p>

<p><a href="http://joschu.net/docs/nuts-and-bolts.pdf">http://joschu.net/docs/nuts-and-bolts.pdf</a></p>

<p><a href="http://amid.fish/reproducing-deep-rl">http://amid.fish/reproducing-deep-rl</a></p>

<p><a href="https://www.alexirpan.com/2018/02/14/rl-hard.html">https://www.alexirpan.com/2018/02/14/rl-hard.html</a></p>

<p><a href="https://openai.com/blog/science-of-ai/">https://openai.com/blog/science-of-ai/</a></p>

<p><a href="https://costa.sh/blog-the-32-implementation-details-of-ppo.html">https://costa.sh/blog-the-32-implementation-details-of-ppo.html</a></p>

<h1 id="why-it-matters">
<a class="anchor" href="#why-it-matters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why it matters?</h1>

<ul>
  <li>Reproducibility, <strong>especially in Deep RL</strong>, is hard (sources above).</li>
  <li>
<strong>Multiple factors</strong> affect the results: random seed, hyperparameters, code-level optimizations.</li>
  <li>It is common to report the <strong>best of N</strong> results, which makes misleading claims.</li>
</ul>

<p><img src="/images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%201.png" alt="Untitled"></p>

<p>Agarwal et al., 2021</p>

<h1 id="statistical-power-analysis-colas-et-al-2017-paper">
<a class="anchor" href="#statistical-power-analysis-colas-et-al-2017-paper" aria-hidden="true"><span class="octicon octicon-link"></span></a>Statistical Power Analysis (Colas et al., 2017 paper)</h1>

<p>Consider two algorithms below. The name of the algorithm is not important. The mean and 95% confidence interval are averaged over <strong>5 seeds</strong>. Our concern: is algorithm 1 better than 2?</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%202.png" alt="Untitled"></p>

<p>The measure of performance: the average cumulated reward over last 100 evaluation episodes. It seems like Algo 1 is better than Algo 2.</p>

<h2 id="statistical-problem">
<a class="anchor" href="#statistical-problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>Statistical problem</h2>

<p>The performance can be modeled as a <em>random variable</em> $X$. Running this algorithm results in $x^i$. Run for N times, we obtain a statistical sample $x = (x^1,…,x^N)$.</p>

<p>A random variable is characterized by its mean $\mu$ and standard deviation $\sigma$. The real values are unknown, so we compute the unbiased estimations $\overline{x}=\sum_{i=1}^n x^i$ and $s \approx \sqrt{\frac{\sum_{i+1}^N (x^i - \overline{x})^2}{N-1}}$. The larger the $N$, the more confident one can be in the estimations.</p>

<p>Here, two algorithms with respective performances $X_1$ and $X_2$ are compared. If they follow normal distributions, then $X_{\text{diff}} = X_1 - X_2$ also follows a normal distribution with parameters $\sigma_{\text{diff}} = \sqrt{(\sigma_1^2 + \sigma_2^2)}$ and $\mu_{\text{diff}} = \mu_1 - \mu_2$.</p>

<p>In this case, the estimator of the mean of $X_{\text{diff}}$ is $\overline{x}<em>{\text{diff}} = \overline{x}_1 - \overline{x_2}$ and the estimator of $\sigma</em>{\text{diff}}$ is $s_{\text{diff}} = \sqrt{s_1^2 + s_2^2}$. The effect size $\epsilon$ can be defined as $\epsilon = \mu_1 - \mu_2$.</p>

<p>Testing $\epsilon$ between two algorithms is mathematically equivalent to testing a difference between $\mu_{\text{diff}}$ and 0.</p>

<h2 id="difference-test">
<a class="anchor" href="#difference-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Difference test</h2>

<p>We define the null hypothesis $H_0$and the alternate hypothesis $H_a$ using the two-tail case:</p>

<ul>
  <li>$H_0: \mu_{\text{diff}} = 0$</li>
  <li>$H_a: \mu_{\text{diff}} \neq 0$</li>
</ul>

<p>When we have an assumption about which algorithm performs better (say, Algo 1), we can use the one-tail version:</p>

<ul>
  <li>$H_0: \mu_{\text{diff}} \leq 0$</li>
  <li>$H_a: \mu_{\text{diff}} &gt; 0$</li>
</ul>

<p>At first, <strong>we assume the null hypothesis</strong>. Once a sample $x_{\text{diff}}$ is sampled from $X_{\text{diff}}$, we can estimate the probability $p$ (called $p$-value) of observing the data as *extreme <strong>(*$\overline{x}_{\text{diff}}$ is far from 0)</strong>, under the null hypothesis assumption. $p$-value answers the question:</p>

<p>How probable is it to observe this sample or a more extreme one, given that there is no true difference in the performances of both algorithms?</p>

<p>We can rewrite it for the one-tail case:</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mtext>-value</mtext><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mtext>diff</mtext></msub><mo>≥</mo><msub><mover accent="true"><mi>x</mi><mo stretchy="true">‾</mo></mover><mtext>diff</mtext></msub><mi mathvariant="normal">∣</mi><msub><mi>H</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p\text{-value} = P(X_{\text{diff}} \geq \overline{x}_{\text{diff}} | H_0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord text"><span class="mord">-value</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">diff</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.63056em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3.55056em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">diff</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>

<p>For the two-tail case:</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mtext>-value</mtext><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mtext>diff</mtext></msub><mo>≥</mo><msub><mover accent="true"><mi>x</mi><mo stretchy="true">‾</mo></mover><mtext>diff</mtext></msub><mi mathvariant="normal">∣</mi><msub><mi>H</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mover accent="true"><mi>x</mi><mo stretchy="true">‾</mo></mover><mtext>diff</mtext></msub><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mtext>diff</mtext></msub><mo>≤</mo><msub><mover accent="true"><mi>x</mi><mo stretchy="true">‾</mo></mover><mtext>diff</mtext></msub><mi mathvariant="normal">∣</mi><msub><mi>H</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mover accent="true"><mi>x</mi><mo stretchy="true">‾</mo></mover><mtext>diff</mtext></msub><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">p\text{-value} = \begin{cases} &amp; P(X_{\text{diff}} \geq \overline{x}_{\text{diff}} | H_0), \overline{x}_{\text{diff}} &gt; 0 \\
&amp; P(X_{\text{diff}} \leq \overline{x}_{\text{diff}} | H_0), \overline{x}_{\text{diff}} \leq 0
\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord text"><span class="mord">-value</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">diff</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.63056em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3.55056em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">diff</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.63056em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3.55056em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">diff</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">diff</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.63056em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3.55056em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">diff</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.63056em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3.55056em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">diff</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>

<p>When this probability becomes really <strong>low</strong>, it means that <strong>it is highly improbable that two algorithms with no performance difference produced the collected</strong> (Algo 1 is different from Algo 2)<strong>.</strong></p>

<p>A difference is called significant at level $\alpha$ when $p$-value &lt; $\alpha$ in the one-tail case, and $\alpha/2$ in the two-tail case. Usually $\alpha=0.05$. However, $\alpha = 0.05$ also means there is a 5% chance we conclude it <strong>wrong</strong>.</p>

<p><strong>In the paper by Colas et al., the authors also suggest an alternate way to test the difference using 95% confidence intervals (95% CIs). However, I will only focus on the t-test for now.</strong></p>

<h2 id="statistical-testing">
<a class="anchor" href="#statistical-testing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Statistical testing</h2>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%203.png" alt="Untitled"></p>

<p>Type-I error: false positive. <strong>Rejects $H_0$ when it is true.</strong></p>

<p>Type-II error: false negative. <strong>Accepts $H_0$ when it is false.</strong></p>

<h2 id="the-t-test-and-welchs-t-test">
<a class="anchor" href="#the-t-test-and-welchs-t-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>The t-test and Welch’s t-test</h2>

<p>The t-test assumes that the variances of both algorithms are <strong>equal</strong>, while Welch’s t-test assumes they are <strong>unequal</strong>. Both tests are equivalent when the std are equal.</p>

<p>The t-test assumes the following:</p>

<ul>
  <li>The scale of data measurements must be continuous and ordinal (can be ranked). This is the case in RL.</li>
  <li>Data is obtained by collecting a representative sample from the population.
This seem reasonable in RL.</li>
  <li>Measurements are independent from one another. This seems reasonable
in RL.</li>
  <li>Data is normally-distributed, or at least bell-shaped.</li>
</ul>

<p>We then compute the $t$-statistic and the degree of freedom $\nu$ using the following equations:</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%204.png" alt="Untitled"></p>

<p>where $x_{\text{diff}} = x_1 - x_2$; $s_1, s_2$ is the empirical standard deviations of the two samples and $N_1, N_2$ are their sizes (which we assume $N_1 = N_2 = N$).</p>

<p>A figure to make sense of these concepts:</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%205.png" alt="Untitled"></p>

<p>$H_0$ assumes $\mu_{\text{diff}} = 0$, so the distribution is centered on 0. $H_a$ assumes a positive difference $\mu_{\text{diff}} = \epsilon$, so the distribution is shifted by the t-value corresponding to $\epsilon$, $t_\epsilon$. We consider the one-tail case, and test for the positive difference.</p>

<p>Using the computed t-statistic and $\nu$, we can compute the $\alpha$ value. $<strong>\alpha$ is enough to declare statistical significance</strong>. With modern software work, we can directly compute t-statistic and $\alpha$ without worrying about $\nu$.</p>

<h2 id="back-to-the-problem">
<a class="anchor" href="#back-to-the-problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>Back to the problem</h2>

<p><img src="/images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%202.png" alt="Untitled"></p>

<p>The measure of performance: the average cumulated reward over last 100 evaluation episodes. It seems like Algo 1 is better than Algo 2. The p-value returned is 0.031, which is lower than $\alpha = 0.05$.</p>

<p>However, <strong>they are the same algorithm: DDPG</strong>. They have the same set of parameters, are evaluated on the same environment (so there is no implementation tricks involved), and are averaged over 5 seeds each.</p>

<h2 id="estimate-the-type-i-error">
<a class="anchor" href="#estimate-the-type-i-error" aria-hidden="true"><span class="octicon octicon-link"></span></a>Estimate the type-I error.</h2>

<p>Experiment: same algorithm, runs for $N = [2, 21]$.</p>

<p><img src="/images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%206.png" alt="Untitled"></p>

<p>So in practice, $N={5, 10}$ works well.</p>

<h1 id="deep-reinforcement-learning-that-matters">
<a class="anchor" href="#deep-reinforcement-learning-that-matters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deep Reinforcement Learning that matters</h1>

<p>Empirical results from Henderson et al., 2017 paper.</p>

<h2 id="reward-scaling">
<a class="anchor" href="#reward-scaling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reward Scaling</h2>

<ul>
  <li>
<strong>Idea</strong>: Multiply the reward by some scalar: $r = \sigma r$.</li>
  <li>
<strong>Why it matters</strong>: this affects action-value function based method like DDPG.</li>
</ul>

<p><img src="/images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%207.png" alt="Untitled"></p>

<p><img src="/images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%208.png" alt="Untitled"></p>

<h2 id="random-seeds-and-trials">
<a class="anchor" href="#random-seeds-and-trials" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random seeds and trials</h2>

<ul>
  <li>
<strong>Idea</strong>: run multiple runs with different random seeds</li>
  <li>
<strong>Why it matters</strong>: environment stochasticity or stochasticity in the learning process, e.g. random weight initialization, Q-value initialization.</li>
</ul>

<p><img src="/images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%209.png" alt="Untitled"></p>

<p>Additional result from Islam et al., 2017 paper:</p>

<p><img src="/images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2010.png" alt="Untitled"></p>

<p><img src="/images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2011.png" alt="Untitled"></p>

<h2 id="environment-variables">
<a class="anchor" href="#environment-variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Environment variables</h2>

<ul>
  <li>Idea: different environment can affect the performance</li>
  <li>Why it matters: although the reward can be high, it can learn undesirable policy.</li>
</ul>

<p>In this figure, HalfCheetah has stable dynamics. Hopper does not have stable dynamics. <strong>Swimmer has a local optima.</strong></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2012.png" alt="Untitled"></p>

<p><a href="https://www.youtube.com/watch?v=lKpUQYjgm80">https://www.youtube.com/watch?v=lKpUQYjgm80</a></p>

<p><a href="https://www.youtube.com/watch?v=ghCo7ERx6qo">https://www.youtube.com/watch?v=ghCo7ERx6qo</a></p>

<p>CoastRunners <strong>does not directly reward the player’s progression around the course</strong>, instead the player earns higher scores by <strong>hitting targets laid out along the route</strong>. We assumed the score the player earned would reflect the informal goal of finishing the race, so we included the game in an internal benchmark designed to measure the performance of reinforcement learning systems on racing games. However, it turned out that the targets were laid out in such a way that the reinforcement learning agent could gain a high score without having to finish the course. This led to some unexpected behavior when we trained an RL agent to play the game.</p>

<p><a href="https://www.youtube.com/watch?v=tlOIHko8ySg&amp;t=1s">https://www.youtube.com/watch?v=tlOIHko8ySg&amp;t=1s</a></p>

<h2 id="implementation-tricks">
<a class="anchor" href="#implementation-tricks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation tricks</h2>

<ul>
  <li>Idea: code-level optimization tricks like advantage normalization, n-steps TD return.</li>
  <li>Why it matters: it drastically changes the result.</li>
</ul>

<p>Consider:</p>

<ul>
  <li>Set 1: <strong>TRPO</strong> from TRPO codebase (Schulman 2015), from PPO codebase(Schulman 2017), and rllib Tensorflow (Duan 2016) codebases.</li>
  <li>Set 2: <strong>DDPG</strong> rllab Theano (Duan 2016), rllabplusplus (Gu 2016), OpenAI Baselines (Plapper 2017).</li>
</ul>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2013.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2014.png" alt="Untitled"></p>

<h1 id="implementation-matters-in-deep-rl-engstorm-et-al-2020-paper">
<a class="anchor" href="#implementation-matters-in-deep-rl-engstorm-et-al-2020-paper" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation Matters in Deep RL (Engstorm et al., 2020 paper)</h1>

<p>Different code-level optimization tricks can lead to (dramatically) <strong>different</strong> results.</p>

<p>Specifically, PPO implementation contains these optimizations that are not (or barely) described in the original paper:</p>

<ol>
  <li>Value function clipping. PPO originally suggests fitting the value network via regression to target values: $L^V = (V_{\theta_t} - V_{targ})^2$. However, the implementation in OpenAI Baselines fits the network with a PPO-like objective:</li>
</ol>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>L</mi><mi>V</mi></msup><mo>=</mo><mi>max</mi><mo>⁡</mo><mrow><mo fence="true">[</mo><mo stretchy="false">(</mo><msub><mi>V</mi><msub><mi>θ</mi><mi>t</mi></msub></msub><mo>−</mo><msub><mi>V</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>c</mi><mi>l</mi><mi>i</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>V</mi><msub><mi>θ</mi><mi>t</mi></msub></msub><mo separator="true">,</mo><msub><mi>V</mi><msub><mi>θ</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></msub><mo>−</mo><mi>ϵ</mi><mo separator="true">,</mo><msub><mi>V</mi><msub><mi>θ</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></msub><mo>+</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mo>−</mo><msub><mi>V</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">L^V = \max \left[ (V_{\theta_t} - V_{targ})^2, (clip(V_{\theta_t}, V_{\theta_{t-1}} - \epsilon, V_{\theta_{t-1}} + \epsilon) - V_{targ})^2 \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8913309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2141179999999998em;vertical-align:-0.35001em;"></span><span class="mop">max</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29634285714285713em;"><span style="top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28055599999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">i</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29634285714285713em;"><span style="top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173142857142857em;"><span style="top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.20252142857142857em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.291765em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">ϵ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173142857142857em;"><span style="top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.20252142857142857em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.291765em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">ϵ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28055599999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span></span></span></span>

<ol>
  <li>Reward scaling. Rewards are divided through by the std of a rolling discounted sum of the rewards.</li>
  <li>Orthogonal initialization and layer scaling.</li>
  <li>Adam learning rate annealing.</li>
  <li>Reward clipping: [-5, 5] or [-10, 10].</li>
  <li>Observation normalization: states are normalized to mean-zero, variance-one vectors before training.</li>
  <li>Observation clipping: like reward.</li>
  <li>Hyperbolic tan (tanh) activations.</li>
  <li>Global gradient clipping: global $\ell_2$-norm less than 0.5.</li>
</ol>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2015.png" alt="Untitled"></p>

<p>The authors then consider a PPO-M (minimal) variant, that <strong>does not use</strong> these optimization tricks, alongside PPO and TRPO, and the TRPO+ variant that uses PPO tricks.</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2016.png" alt="Untitled"></p>

<h2 id="results-comparing-4-algorithms">
<a class="anchor" href="#results-comparing-4-algorithms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results comparing 4 algorithms</h2>

<p>Define:</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2017.png" alt="Untitled"></p>

<p>AAI measures the <strong>maximal effect of switching algorithms</strong>, and ACLI measures the <strong>maximal effect of adding tricks.</strong></p>

<p>We have:</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2018.png" alt="Untitled"></p>

<h1 id="how-to-tune-hyperparameters">
<a class="anchor" href="#how-to-tune-hyperparameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to tune hyperparameters?</h1>

<p>Note: this tuning guide depends on <strong>empirical results</strong>, not theoretical.</p>

<h3 id="network-architecture">
<a class="anchor" href="#network-architecture" aria-hidden="true"><span class="octicon octicon-link"></span></a>Network Architecture</h3>

<p>From Henderson et al., 2017 paper:</p>

<p>Investigate three common architectures: (64, 64), (100, 50, 25) and (400, 30), activation: tanh, ReLU, Leaky ReLU.</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2019.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2020.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2021.png" alt="Untitled"></p>

<p>From Islam et al., 2017 paper: (purpose: to <strong>reproduce</strong> results)</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2022.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2023.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2024.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2025.png" alt="Untitled"></p>

<h3 id="batch-size">
<a class="anchor" href="#batch-size" aria-hidden="true"><span class="octicon octicon-link"></span></a>Batch Size</h3>

<p>From Islam et al., 2017 paper</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2026.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2027.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2028.png" alt="Untitled"></p>

<h3 id="findings-from-andrychowicz-et-al-2021-paper">
<a class="anchor" href="#findings-from-andrychowicz-et-al-2021-paper" aria-hidden="true"><span class="octicon octicon-link"></span></a>Findings from Andrychowicz et al., 2021 paper</h3>

<p>Train <strong>250k agents</strong> in 5 continuous control environments. Each choice is run for 3 random seeds, but the reported results are based on the performance of hundreds of runs.</p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2029.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2030.png" alt="Untitled"></p>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2031.png" alt="Untitled"></p>

<h1 id="suggested-method-to-compare-algorithms">
<a class="anchor" href="#suggested-method-to-compare-algorithms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Suggested method to compare algorithms</h1>

<p>Pseudocode thanks to James MacGlashan (Senior Research Scientist - Sony AI).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trials</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">neval</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">alg1_performance</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">trials</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">train_alg1</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>  <span class="c1"># train for 10,000 time steps, get policy
</span>    <span class="n">eval_performances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">neval</span><span class="p">):</span>
        <span class="n">episode</span> <span class="o">=</span> <span class="n">run_episode</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">avg_episode_reward</span> <span class="o">=</span> <span class="n">compute_avg_reward</span><span class="p">(</span><span class="n">episode</span><span class="p">)</span>
        <span class="n">eval_performances</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_episode_reward</span><span class="p">)</span>
    <span class="n">trial_performance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">eval_performances</span><span class="p">)</span>
    <span class="n">alg1_performance</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">trial_performance</span><span class="p">)</span>

<span class="n">alg2_performance</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">trials</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">train_alg2</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>  <span class="c1"># train for 10,000 time steps, get policy
</span>    <span class="n">eval_performances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">neval</span><span class="p">):</span>
        <span class="n">episode</span> <span class="o">=</span> <span class="n">run_episode</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">avg_reward</span> <span class="o">=</span> <span class="n">compute_avg_reward</span><span class="p">(</span><span class="n">episode</span><span class="p">)</span>
        <span class="n">eval_performances</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_reward</span><span class="p">)</span>
    <span class="n">trial_performance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">eval_performances</span><span class="p">)</span>
    <span class="n">alg2_performance</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">trial_performance</span><span class="p">)</span>

<span class="n">p_value</span> <span class="o">=</span> <span class="n">t_test</span><span class="p">(</span><span class="n">alg1_performance</span><span class="p">,</span> <span class="n">alg2_performance</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="suggestions-and-conclusion">
<a class="anchor" href="#suggestions-and-conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Suggestions and Conclusion</h1>

<blockquote>
  <p>In general, however, the most important step to reproducibility is to <strong>report all</strong> hyperparameters, implementation details, experimental setup, and evaluation methods for both baseline comparison methods and novel work. Without the publication of implementations and related details, wasted effort on reproducing state-of-the-art works will plague the community and slow down progress.</p>
</blockquote>

<p><img src="../images/Making%20your%20Deep%20RL%20matters%20c01bfd91a2dc4cef8c405348e5a7d7dc/Untitled%2046.png" alt="Untitled"></p>

<blockquote>
  <p>Overall, our results highlight the necessity of designing deep RL methods in a modular manner. When building algorithms, we should understand precisely how each component impacts agent training—both in terms of overall performance and underlying algorithmic behavior. It is impossible to properly attribute successes and failures in the  complicated systems that make up deep RL methods without such diligence. More broadly, our findings suggest that developing an RL toolkit will require moving beyond the current <strong>benchmark-driven</strong> evaluation model to a more fine-grained understanding of deep RL methods.</p>
</blockquote>

<p>Note: Stable-Baselines3 has all these recommendations implemented by default.</p>

  </div><a class="u-url" href="/blog/drl/2021/09/25/Making-your-Deep-RL-matters.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/minhlong94" target="_blank" title="minhlong94"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
